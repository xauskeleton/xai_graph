# T√™n file: src/evaluate.py

import torch
import torch.nn as nn
from transformers import AutoTokenizer
from tqdm import tqdm
import os

# Import t·ª´ c√°c file c·ªßa b·∫°n
from data_loader import get_loader
from model import ImageCaptioningModel
from utils import load_checkpoint # Ch·ªâ c·∫ßn load

# --- C·∫§U H√åNH (CONFIG) ---
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ƒêang s·ª≠ d·ª•ng thi·∫øt b·ªã: {DEVICE}")

# ƒê∆∞·ªùng d·∫´n
TEST_JSON_PATH = 'data/test_data.json'
TEST_IMAGE_DIR = 'data/test/' 

# Hyperparameters (PH·∫¢I GI·ªêNG H·ªÜT file train.py)
VOCAB_SIZE = 30522 
EMBED_DIM = 256
HIDDEN_DIM = 512
NUM_OBJECTS = 36
GNN_LAYERS = 3
GNN_HEADS = 4
K_NEIGHBORS = 10
BATCH_SIZE = 16

# Checkpoint
CHECKPOINT_FILE = "checkpoints/best_model.pth.tar"

# --- H√ÄM ƒê√ÅNH GI√Å ---
def evaluate():
    
    print("--- ü§ñ ƒêang t·∫£i Tokenizer (PhoBERT) ---")
    tokenizer = AutoTokenizer.from_pretrained('vinai/phobert-base')
    VOCAB_SIZE = tokenizer.vocab_size
    PAD_TOKEN_ID = tokenizer.pad_token_id

    print("\n--- üß™ ƒêang kh·ªüi t·∫°o DataLoader cho T·∫¨P KI·ªÇM TRA (Test) ---")
    test_loader, test_dataset = get_loader(
        TEST_JSON_PATH, TEST_IMAGE_DIR, tokenizer, 
        BATCH_SIZE, shuffle=False, num_workers=4
    )
    print(f"‚úÖ T·∫£i th√†nh c√¥ng! {len(test_dataset)} m·∫´u ki·ªÉm tra.")

    # --- Kh·ªüi t·∫°o Model, Loss ---
    print("\n--- üõ†Ô∏è ƒêang kh·ªüi t·∫°o Model ---")
    model = ImageCaptioningModel(
        vocab_size=VOCAB_SIZE,
        embed_dim=EMBED_DIM,
        hidden_dim=HIDDEN_DIM,
        num_objects=NUM_OBJECTS,
        gnn_layers=GNN_LAYERS,
        gnn_heads=GNN_HEADS,
        k_neighbors=K_NEIGHBORS
    ).to(DEVICE)
    
    criterion = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN_ID)
    
    # --- T·∫¢I CHECKPOINT ---
    if not os.path.exists(CHECKPOINT_FILE):
        print(f"‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y checkpoint t·∫°i '{CHECKPOINT_FILE}'")
        print("Vui l√≤ng ch·∫°y train.py tr∆∞·ªõc!")
        return
        
    print(f"--- üíæ ƒêang t·∫£i checkpoint t·ª´ {CHECKPOINT_FILE} ---")
    # Ch√∫ng ta kh√¥ng c·∫ßn load optimizer v√¨ kh√¥ng train
    load_checkpoint(model, CHECKPOINT_FILE, device=DEVICE)

    # --- B·∫Øt ƒë·∫ßu v√≤ng l·∫∑p ƒê√°nh gi√° ---
    print("\n--- üìä B·∫Øt ƒë·∫ßu ƒê√°nh gi√° Loss tr√™n t·∫≠p Test ---")
    model.eval() # R·∫•t quan tr·ªçng!
    
    total_test_loss = 0.0
    
    with torch.no_grad(): # T·∫Øt gradient
        loop = tqdm(test_loader, leave=True)
        for images, token_batch in loop:
            images = images.to(DEVICE)
            input_ids = token_batch['input_ids'].to(DEVICE)
            
            captions_input = input_ids[:, :-1]
            captions_target = input_ids[:, 1:]
            
            outputs = model(images, captions_input)
            loss = criterion(
                outputs.reshape(-1, VOCAB_SIZE),
                captions_target.reshape(-1)
            )
            total_test_loss += loss.item()
            loop.set_postfix(test_loss=loss.item())

    avg_test_loss = total_test_loss / len(test_loader)
    
    print("\n" + "=" * 50)
    print("--- K·∫æT QU·∫¢ ƒê√ÅNH GI√Å HO√ÄN T·∫§T ---")
    print(f"  Average Test Loss: {avg_test_loss:.4f}")
    print("=" * 50)

if __name__ == "__main__":
    evaluate()