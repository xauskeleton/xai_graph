import os
import json
import torch
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import torchvision.transforms as transforms
from transformers import AutoTokenizer

class KTVICDataset(Dataset):
    def __init__(self, json_file, image_dir, transform=None):
        self.image_dir = image_dir
        self.transform = transform
        
        self.caption_key = "caption" 

        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        self.image_id_to_filename = {}
        for img_info in data['images']:
            self.image_id_to_filename[img_info['id']] = img_info['filename']

        self.annotations = data['annotations']

    def __len__(self):
        return len(self.annotations)

    def __getitem__(self, index):
        ann = self.annotations[index]
        caption = ann[self.caption_key]
        image_id = ann['image_id']
        filename = self.image_id_to_filename[image_id]
        image_path = os.path.join(self.image_dir, filename)
        image = Image.open(image_path).convert('RGB')

        if self.transform:
            image = self.transform(image)

        return image, caption

class CollateFn:

    def __init__(self, tokenizer, max_length=128):
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __call__(self, batch):

        #T√°ch ri√™ng ·∫£nh v√† caption
        images = [item[0] for item in batch]
        captions = [item[1] for item in batch]

        images_batch_list = images

        tokenized_batch = self.tokenizer(
            captions,
            padding=True,
            truncation=True,
            max_length=self.max_length,
            return_tensors="pt"
        )

        return images_batch_list, tokenized_batch

def get_loader(json_file, image_dir, tokenizer, batch_size=32, shuffle=True, num_workers=4):
    
    transform = transforms.Compose([
        transforms.ToTensor()
    ])

    dataset = KTVICDataset(
        json_file=json_file,
        image_dir=image_dir,
        transform=transform,
    )

    collate_fn = CollateFn(tokenizer)

    data_loader = DataLoader(
        dataset=dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        num_workers=num_workers,
        collate_fn=collate_fn 
    )

    return data_loader, dataset


if __name__ == '__main__':
    
    # --- C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n (H√£y s·ª≠a l·∫°i cho ƒë√∫ng) ---
    TRAIN_JSON_PATH = 'data/train_data.json' 
    TRAIN_IMAGE_DIR = 'data/train/'
    TEST_JSON_PATH = 'data/test_data.json'
    TEST_IMAGE_DIR = 'data/test/' 

    BATCH_SIZE = 4
    
    print("--- ü§ñ ƒêang t·∫£i Tokenizer (PhoBERT) ---")
    try:
        # (C·∫ßn c√†i ƒë·∫∑t: pip install transformers)
        tokenizer = AutoTokenizer.from_pretrained('vinai/phobert-base')
        print(f"‚úÖ T·∫£i tokenizer th√†nh c√¥ng! Vocab size: {tokenizer.vocab_size}")

        # --- Test TRAIN Loader ---
        print("\n--- üöÄ ƒêang kh·ªüi t·∫°o DataLoader cho T·∫¨P HU·∫§N LUY·ªÜN (Train) ---")
        train_loader, train_dataset = get_loader(
            json_file=TRAIN_JSON_PATH,
            image_dir=TRAIN_IMAGE_DIR,
            tokenizer=tokenizer,
            batch_size=BATCH_SIZE,
            shuffle=True
        )
        print(f"‚úÖ T·∫£i th√†nh c√¥ng! T·ªïng s·ªë m·∫´u hu·∫•n luy·ªán: {len(train_dataset)}")
        
        # L·∫•y th·ª≠ 1 batch train
        train_images_list, train_tokens = next(iter(train_loader))
        
        print(f"   -> Ki·ªÉu d·ªØ li·ªáu batch ·∫£nh: {type(train_images_list)}")
        print(f"   -> S·ªë l∆∞·ª£ng ·∫£nh trong batch: {len(train_images_list)}")
        print(f"   -> K√≠ch th∆∞·ªõc ·∫£nh ƒë·∫ßu ti√™n: {train_images_list[0].shape}")
        
        print(f"   -> D·ªØ li·ªáu text (dictionary keys): {train_tokens.keys()}")
        print(f"   -> K√≠ch th∆∞·ªõc input_ids: {train_tokens['input_ids'].shape}")
        
        first_caption_text = tokenizer.decode(train_tokens['input_ids'][0], skip_special_tokens=False)
        print(f"   -> Caption 0 (d·∫°ng ch·ªØ): {first_caption_text}")

        # --- Test TEST Loader ---
        print("\n--- üß™ ƒêang kh·ªüi t·∫°o DataLoader cho T·∫¨P KI·ªÇM TRA (Test) ---")
        test_loader, test_dataset = get_loader(
            json_file=TEST_JSON_PATH,
            image_dir=TEST_IMAGE_DIR,
            tokenizer=tokenizer,
            batch_size=BATCH_SIZE,
            shuffle=False
        )
        print(f"‚úÖ T·∫£i th√†nh c√¥ng! T·ªïng s·ªë m·∫´u ki·ªÉm tra: {len(test_dataset)}")

        # L·∫•y th·ª≠ 1 batch test
        test_images_list, test_tokens = next(iter(test_loader))
        print(f"   -> Ki·ªÉu d·ªØ li·ªáu batch ·∫£nh test: {type(test_images_list)}")
        print(f"   -> S·ªë l∆∞·ª£ng ·∫£nh trong batch: {len(test_images_list)}")
        print(f"   -> K√≠ch th∆∞·ªõc ·∫£nh ƒë·∫ßu ti√™n (test): {test_images_list[0].shape}")
        print(f"   -> K√≠ch th∆∞·ªõc input_ids (test): {test_tokens['input_ids'].shape}")

    except ImportError:
        print("\n‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y th∆∞ vi·ªán 'transformers'.")
        print("   Vui l√≤ng c√†i ƒë·∫∑t b·∫±ng l·ªánh: pip install transformers")
    except FileNotFoundError as e:
        print(f"\n‚ùå L·ªñI: KH√îNG T√åM TH·∫§Y FILE. H√£y ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n!")
        print(f"   Chi ti·∫øt l·ªói: {e}")
        print(f"   C√°c ƒë∆∞·ªùng d·∫´n ƒëang d√πng:")
        print(f"   TRAIN_JSON_PATH: '{TRAIN_JSON_PATH}'")
        print(f"   TRAIN_IMAGE_DIR: '{TRAIN_IMAGE_DIR}'")
        print(f"   TEST_JSON_PATH: '{TEST_JSON_PATH}'")
        print(f"   TEST_IMAGE_DIR: '{TEST_IMAGE_DIR}'")
    except Exception as e:
        print(f"\n‚ùå L·ªñI KH√ÅC: {e}")